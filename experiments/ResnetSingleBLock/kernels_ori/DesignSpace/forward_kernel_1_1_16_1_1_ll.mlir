module attributes {llvm.data_layout = ""} {
  llvm.func @forward_kernel_1(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr) attributes {Kernel, forward_kernel_1} {
    %0 = llvm.mlir.constant(1.000000e-05 : f64) : f64
    %1 = llvm.mlir.constant(16 : index) : i64
    %2 = llvm.mlir.constant(5.000000e-01 : f32) : f32
    %3 = llvm.mlir.constant(1 : i32) : i32
    %4 = llvm.mlir.constant(1597463007 : i32) : i32
    %5 = llvm.mlir.constant(1.500000e+00 : f32) : f32
    %6 = llvm.mlir.constant(2 : index) : i64
    %7 = llvm.mlir.constant(3 : index) : i64
    %8 = llvm.mlir.constant(4 : index) : i64
    %9 = llvm.mlir.constant(5 : index) : i64
    %10 = llvm.mlir.constant(6 : index) : i64
    %11 = llvm.mlir.constant(7 : index) : i64
    %12 = llvm.mlir.constant(8 : index) : i64
    %13 = llvm.mlir.constant(9 : index) : i64
    %14 = llvm.mlir.constant(10 : index) : i64
    %15 = llvm.mlir.constant(11 : index) : i64
    %16 = llvm.mlir.constant(12 : index) : i64
    %17 = llvm.mlir.constant(13 : index) : i64
    %18 = llvm.mlir.constant(14 : index) : i64
    %19 = llvm.mlir.constant(15 : index) : i64
    %20 = llvm.mlir.constant(112 : index) : i64
    %21 = llvm.mlir.constant(12544 : index) : i64
    %22 = llvm.mlir.constant(802816 : index) : i64
    %23 = llvm.mlir.constant(1 : index) : i64
    %24 = llvm.mlir.constant(0 : index) : i64
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    llvm.br ^bb2(%24 : i64)
  ^bb2(%25: i64):  // 2 preds: ^bb1, ^bb6
    %26 = llvm.icmp "slt" %25, %1 : i64
    llvm.cond_br %26, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %27 = llvm.load %arg0 : !llvm.ptr -> f32
    %28 = llvm.load %arg1 : !llvm.ptr -> f32
    %29 = llvm.load %arg2 : !llvm.ptr -> f32
    %30 = llvm.load %arg3 : !llvm.ptr -> f32
    llvm.br ^bb4(%24 : i64)
  ^bb4(%31: i64):  // 2 preds: ^bb3, ^bb5
    %32 = llvm.icmp "slt" %31, %20 : i64
    llvm.cond_br %32, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %33 = llvm.mul %24, %22  : i64
    %34 = llvm.mul %24, %21  : i64
    %35 = llvm.add %33, %34  : i64
    %36 = llvm.mul %25, %20  : i64
    %37 = llvm.add %35, %36  : i64
    %38 = llvm.add %37, %31  : i64
    %39 = llvm.getelementptr %arg4[%38] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %40 = llvm.load %39 : !llvm.ptr -> f32
    %41 = llvm.fptrunc %0 : f64 to f32
    %42 = llvm.fadd %30, %41  : f32
    %43 = llvm.fmul %42, %2  : f32
    %44 = llvm.bitcast %42 : f32 to i32
    %45 = llvm.lshr %44, %3  : i32
    %46 = llvm.sub %4, %45  : i32
    %47 = llvm.bitcast %46 : i32 to f32
    %48 = llvm.fmul %47, %47  : f32
    %49 = llvm.fmul %48, %43  : f32
    %50 = llvm.fsub %5, %49  : f32
    %51 = llvm.fmul %50, %48  : f32
    %52 = llvm.fsub %40, %29  : f32
    %53 = llvm.fmul %52, %51  : f32
    %54 = llvm.fmul %53, %27  : f32
    %55 = llvm.fadd %54, %28  : f32
    %56 = llvm.mul %24, %22  : i64
    %57 = llvm.mul %24, %21  : i64
    %58 = llvm.add %56, %57  : i64
    %59 = llvm.mul %25, %20  : i64
    %60 = llvm.add %58, %59  : i64
    %61 = llvm.add %60, %31  : i64
    %62 = llvm.getelementptr %arg5[%61] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %55, %62 : f32, !llvm.ptr
    %63 = llvm.add %31, %23  : i64
    %64 = llvm.mul %24, %22  : i64
    %65 = llvm.mul %24, %21  : i64
    %66 = llvm.add %64, %65  : i64
    %67 = llvm.mul %25, %20  : i64
    %68 = llvm.add %66, %67  : i64
    %69 = llvm.add %68, %63  : i64
    %70 = llvm.getelementptr %arg4[%69] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %71 = llvm.load %70 : !llvm.ptr -> f32
    %72 = llvm.fptrunc %0 : f64 to f32
    %73 = llvm.fadd %30, %72  : f32
    %74 = llvm.fmul %73, %2  : f32
    %75 = llvm.bitcast %73 : f32 to i32
    %76 = llvm.lshr %75, %3  : i32
    %77 = llvm.sub %4, %76  : i32
    %78 = llvm.bitcast %77 : i32 to f32
    %79 = llvm.fmul %78, %78  : f32
    %80 = llvm.fmul %79, %74  : f32
    %81 = llvm.fsub %5, %80  : f32
    %82 = llvm.fmul %81, %79  : f32
    %83 = llvm.fsub %71, %29  : f32
    %84 = llvm.fmul %83, %82  : f32
    %85 = llvm.fmul %84, %27  : f32
    %86 = llvm.fadd %85, %28  : f32
    %87 = llvm.mul %24, %22  : i64
    %88 = llvm.mul %24, %21  : i64
    %89 = llvm.add %87, %88  : i64
    %90 = llvm.mul %25, %20  : i64
    %91 = llvm.add %89, %90  : i64
    %92 = llvm.add %91, %63  : i64
    %93 = llvm.getelementptr %arg5[%92] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %86, %93 : f32, !llvm.ptr
    %94 = llvm.add %31, %6  : i64
    %95 = llvm.mul %24, %22  : i64
    %96 = llvm.mul %24, %21  : i64
    %97 = llvm.add %95, %96  : i64
    %98 = llvm.mul %25, %20  : i64
    %99 = llvm.add %97, %98  : i64
    %100 = llvm.add %99, %94  : i64
    %101 = llvm.getelementptr %arg4[%100] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %102 = llvm.load %101 : !llvm.ptr -> f32
    %103 = llvm.fptrunc %0 : f64 to f32
    %104 = llvm.fadd %30, %103  : f32
    %105 = llvm.fmul %104, %2  : f32
    %106 = llvm.bitcast %104 : f32 to i32
    %107 = llvm.lshr %106, %3  : i32
    %108 = llvm.sub %4, %107  : i32
    %109 = llvm.bitcast %108 : i32 to f32
    %110 = llvm.fmul %109, %109  : f32
    %111 = llvm.fmul %110, %105  : f32
    %112 = llvm.fsub %5, %111  : f32
    %113 = llvm.fmul %112, %110  : f32
    %114 = llvm.fsub %102, %29  : f32
    %115 = llvm.fmul %114, %113  : f32
    %116 = llvm.fmul %115, %27  : f32
    %117 = llvm.fadd %116, %28  : f32
    %118 = llvm.mul %24, %22  : i64
    %119 = llvm.mul %24, %21  : i64
    %120 = llvm.add %118, %119  : i64
    %121 = llvm.mul %25, %20  : i64
    %122 = llvm.add %120, %121  : i64
    %123 = llvm.add %122, %94  : i64
    %124 = llvm.getelementptr %arg5[%123] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %117, %124 : f32, !llvm.ptr
    %125 = llvm.add %31, %7  : i64
    %126 = llvm.mul %24, %22  : i64
    %127 = llvm.mul %24, %21  : i64
    %128 = llvm.add %126, %127  : i64
    %129 = llvm.mul %25, %20  : i64
    %130 = llvm.add %128, %129  : i64
    %131 = llvm.add %130, %125  : i64
    %132 = llvm.getelementptr %arg4[%131] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %133 = llvm.load %132 : !llvm.ptr -> f32
    %134 = llvm.fptrunc %0 : f64 to f32
    %135 = llvm.fadd %30, %134  : f32
    %136 = llvm.fmul %135, %2  : f32
    %137 = llvm.bitcast %135 : f32 to i32
    %138 = llvm.lshr %137, %3  : i32
    %139 = llvm.sub %4, %138  : i32
    %140 = llvm.bitcast %139 : i32 to f32
    %141 = llvm.fmul %140, %140  : f32
    %142 = llvm.fmul %141, %136  : f32
    %143 = llvm.fsub %5, %142  : f32
    %144 = llvm.fmul %143, %141  : f32
    %145 = llvm.fsub %133, %29  : f32
    %146 = llvm.fmul %145, %144  : f32
    %147 = llvm.fmul %146, %27  : f32
    %148 = llvm.fadd %147, %28  : f32
    %149 = llvm.mul %24, %22  : i64
    %150 = llvm.mul %24, %21  : i64
    %151 = llvm.add %149, %150  : i64
    %152 = llvm.mul %25, %20  : i64
    %153 = llvm.add %151, %152  : i64
    %154 = llvm.add %153, %125  : i64
    %155 = llvm.getelementptr %arg5[%154] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %148, %155 : f32, !llvm.ptr
    %156 = llvm.add %31, %8  : i64
    %157 = llvm.mul %24, %22  : i64
    %158 = llvm.mul %24, %21  : i64
    %159 = llvm.add %157, %158  : i64
    %160 = llvm.mul %25, %20  : i64
    %161 = llvm.add %159, %160  : i64
    %162 = llvm.add %161, %156  : i64
    %163 = llvm.getelementptr %arg4[%162] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %164 = llvm.load %163 : !llvm.ptr -> f32
    %165 = llvm.fptrunc %0 : f64 to f32
    %166 = llvm.fadd %30, %165  : f32
    %167 = llvm.fmul %166, %2  : f32
    %168 = llvm.bitcast %166 : f32 to i32
    %169 = llvm.lshr %168, %3  : i32
    %170 = llvm.sub %4, %169  : i32
    %171 = llvm.bitcast %170 : i32 to f32
    %172 = llvm.fmul %171, %171  : f32
    %173 = llvm.fmul %172, %167  : f32
    %174 = llvm.fsub %5, %173  : f32
    %175 = llvm.fmul %174, %172  : f32
    %176 = llvm.fsub %164, %29  : f32
    %177 = llvm.fmul %176, %175  : f32
    %178 = llvm.fmul %177, %27  : f32
    %179 = llvm.fadd %178, %28  : f32
    %180 = llvm.mul %24, %22  : i64
    %181 = llvm.mul %24, %21  : i64
    %182 = llvm.add %180, %181  : i64
    %183 = llvm.mul %25, %20  : i64
    %184 = llvm.add %182, %183  : i64
    %185 = llvm.add %184, %156  : i64
    %186 = llvm.getelementptr %arg5[%185] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %179, %186 : f32, !llvm.ptr
    %187 = llvm.add %31, %9  : i64
    %188 = llvm.mul %24, %22  : i64
    %189 = llvm.mul %24, %21  : i64
    %190 = llvm.add %188, %189  : i64
    %191 = llvm.mul %25, %20  : i64
    %192 = llvm.add %190, %191  : i64
    %193 = llvm.add %192, %187  : i64
    %194 = llvm.getelementptr %arg4[%193] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %195 = llvm.load %194 : !llvm.ptr -> f32
    %196 = llvm.fptrunc %0 : f64 to f32
    %197 = llvm.fadd %30, %196  : f32
    %198 = llvm.fmul %197, %2  : f32
    %199 = llvm.bitcast %197 : f32 to i32
    %200 = llvm.lshr %199, %3  : i32
    %201 = llvm.sub %4, %200  : i32
    %202 = llvm.bitcast %201 : i32 to f32
    %203 = llvm.fmul %202, %202  : f32
    %204 = llvm.fmul %203, %198  : f32
    %205 = llvm.fsub %5, %204  : f32
    %206 = llvm.fmul %205, %203  : f32
    %207 = llvm.fsub %195, %29  : f32
    %208 = llvm.fmul %207, %206  : f32
    %209 = llvm.fmul %208, %27  : f32
    %210 = llvm.fadd %209, %28  : f32
    %211 = llvm.mul %24, %22  : i64
    %212 = llvm.mul %24, %21  : i64
    %213 = llvm.add %211, %212  : i64
    %214 = llvm.mul %25, %20  : i64
    %215 = llvm.add %213, %214  : i64
    %216 = llvm.add %215, %187  : i64
    %217 = llvm.getelementptr %arg5[%216] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %210, %217 : f32, !llvm.ptr
    %218 = llvm.add %31, %10  : i64
    %219 = llvm.mul %24, %22  : i64
    %220 = llvm.mul %24, %21  : i64
    %221 = llvm.add %219, %220  : i64
    %222 = llvm.mul %25, %20  : i64
    %223 = llvm.add %221, %222  : i64
    %224 = llvm.add %223, %218  : i64
    %225 = llvm.getelementptr %arg4[%224] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %226 = llvm.load %225 : !llvm.ptr -> f32
    %227 = llvm.fptrunc %0 : f64 to f32
    %228 = llvm.fadd %30, %227  : f32
    %229 = llvm.fmul %228, %2  : f32
    %230 = llvm.bitcast %228 : f32 to i32
    %231 = llvm.lshr %230, %3  : i32
    %232 = llvm.sub %4, %231  : i32
    %233 = llvm.bitcast %232 : i32 to f32
    %234 = llvm.fmul %233, %233  : f32
    %235 = llvm.fmul %234, %229  : f32
    %236 = llvm.fsub %5, %235  : f32
    %237 = llvm.fmul %236, %234  : f32
    %238 = llvm.fsub %226, %29  : f32
    %239 = llvm.fmul %238, %237  : f32
    %240 = llvm.fmul %239, %27  : f32
    %241 = llvm.fadd %240, %28  : f32
    %242 = llvm.mul %24, %22  : i64
    %243 = llvm.mul %24, %21  : i64
    %244 = llvm.add %242, %243  : i64
    %245 = llvm.mul %25, %20  : i64
    %246 = llvm.add %244, %245  : i64
    %247 = llvm.add %246, %218  : i64
    %248 = llvm.getelementptr %arg5[%247] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %241, %248 : f32, !llvm.ptr
    %249 = llvm.add %31, %11  : i64
    %250 = llvm.mul %24, %22  : i64
    %251 = llvm.mul %24, %21  : i64
    %252 = llvm.add %250, %251  : i64
    %253 = llvm.mul %25, %20  : i64
    %254 = llvm.add %252, %253  : i64
    %255 = llvm.add %254, %249  : i64
    %256 = llvm.getelementptr %arg4[%255] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %257 = llvm.load %256 : !llvm.ptr -> f32
    %258 = llvm.fptrunc %0 : f64 to f32
    %259 = llvm.fadd %30, %258  : f32
    %260 = llvm.fmul %259, %2  : f32
    %261 = llvm.bitcast %259 : f32 to i32
    %262 = llvm.lshr %261, %3  : i32
    %263 = llvm.sub %4, %262  : i32
    %264 = llvm.bitcast %263 : i32 to f32
    %265 = llvm.fmul %264, %264  : f32
    %266 = llvm.fmul %265, %260  : f32
    %267 = llvm.fsub %5, %266  : f32
    %268 = llvm.fmul %267, %265  : f32
    %269 = llvm.fsub %257, %29  : f32
    %270 = llvm.fmul %269, %268  : f32
    %271 = llvm.fmul %270, %27  : f32
    %272 = llvm.fadd %271, %28  : f32
    %273 = llvm.mul %24, %22  : i64
    %274 = llvm.mul %24, %21  : i64
    %275 = llvm.add %273, %274  : i64
    %276 = llvm.mul %25, %20  : i64
    %277 = llvm.add %275, %276  : i64
    %278 = llvm.add %277, %249  : i64
    %279 = llvm.getelementptr %arg5[%278] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %272, %279 : f32, !llvm.ptr
    %280 = llvm.add %31, %12  : i64
    %281 = llvm.mul %24, %22  : i64
    %282 = llvm.mul %24, %21  : i64
    %283 = llvm.add %281, %282  : i64
    %284 = llvm.mul %25, %20  : i64
    %285 = llvm.add %283, %284  : i64
    %286 = llvm.add %285, %280  : i64
    %287 = llvm.getelementptr %arg4[%286] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %288 = llvm.load %287 : !llvm.ptr -> f32
    %289 = llvm.fptrunc %0 : f64 to f32
    %290 = llvm.fadd %30, %289  : f32
    %291 = llvm.fmul %290, %2  : f32
    %292 = llvm.bitcast %290 : f32 to i32
    %293 = llvm.lshr %292, %3  : i32
    %294 = llvm.sub %4, %293  : i32
    %295 = llvm.bitcast %294 : i32 to f32
    %296 = llvm.fmul %295, %295  : f32
    %297 = llvm.fmul %296, %291  : f32
    %298 = llvm.fsub %5, %297  : f32
    %299 = llvm.fmul %298, %296  : f32
    %300 = llvm.fsub %288, %29  : f32
    %301 = llvm.fmul %300, %299  : f32
    %302 = llvm.fmul %301, %27  : f32
    %303 = llvm.fadd %302, %28  : f32
    %304 = llvm.mul %24, %22  : i64
    %305 = llvm.mul %24, %21  : i64
    %306 = llvm.add %304, %305  : i64
    %307 = llvm.mul %25, %20  : i64
    %308 = llvm.add %306, %307  : i64
    %309 = llvm.add %308, %280  : i64
    %310 = llvm.getelementptr %arg5[%309] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %303, %310 : f32, !llvm.ptr
    %311 = llvm.add %31, %13  : i64
    %312 = llvm.mul %24, %22  : i64
    %313 = llvm.mul %24, %21  : i64
    %314 = llvm.add %312, %313  : i64
    %315 = llvm.mul %25, %20  : i64
    %316 = llvm.add %314, %315  : i64
    %317 = llvm.add %316, %311  : i64
    %318 = llvm.getelementptr %arg4[%317] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %319 = llvm.load %318 : !llvm.ptr -> f32
    %320 = llvm.fptrunc %0 : f64 to f32
    %321 = llvm.fadd %30, %320  : f32
    %322 = llvm.fmul %321, %2  : f32
    %323 = llvm.bitcast %321 : f32 to i32
    %324 = llvm.lshr %323, %3  : i32
    %325 = llvm.sub %4, %324  : i32
    %326 = llvm.bitcast %325 : i32 to f32
    %327 = llvm.fmul %326, %326  : f32
    %328 = llvm.fmul %327, %322  : f32
    %329 = llvm.fsub %5, %328  : f32
    %330 = llvm.fmul %329, %327  : f32
    %331 = llvm.fsub %319, %29  : f32
    %332 = llvm.fmul %331, %330  : f32
    %333 = llvm.fmul %332, %27  : f32
    %334 = llvm.fadd %333, %28  : f32
    %335 = llvm.mul %24, %22  : i64
    %336 = llvm.mul %24, %21  : i64
    %337 = llvm.add %335, %336  : i64
    %338 = llvm.mul %25, %20  : i64
    %339 = llvm.add %337, %338  : i64
    %340 = llvm.add %339, %311  : i64
    %341 = llvm.getelementptr %arg5[%340] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %334, %341 : f32, !llvm.ptr
    %342 = llvm.add %31, %14  : i64
    %343 = llvm.mul %24, %22  : i64
    %344 = llvm.mul %24, %21  : i64
    %345 = llvm.add %343, %344  : i64
    %346 = llvm.mul %25, %20  : i64
    %347 = llvm.add %345, %346  : i64
    %348 = llvm.add %347, %342  : i64
    %349 = llvm.getelementptr %arg4[%348] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %350 = llvm.load %349 : !llvm.ptr -> f32
    %351 = llvm.fptrunc %0 : f64 to f32
    %352 = llvm.fadd %30, %351  : f32
    %353 = llvm.fmul %352, %2  : f32
    %354 = llvm.bitcast %352 : f32 to i32
    %355 = llvm.lshr %354, %3  : i32
    %356 = llvm.sub %4, %355  : i32
    %357 = llvm.bitcast %356 : i32 to f32
    %358 = llvm.fmul %357, %357  : f32
    %359 = llvm.fmul %358, %353  : f32
    %360 = llvm.fsub %5, %359  : f32
    %361 = llvm.fmul %360, %358  : f32
    %362 = llvm.fsub %350, %29  : f32
    %363 = llvm.fmul %362, %361  : f32
    %364 = llvm.fmul %363, %27  : f32
    %365 = llvm.fadd %364, %28  : f32
    %366 = llvm.mul %24, %22  : i64
    %367 = llvm.mul %24, %21  : i64
    %368 = llvm.add %366, %367  : i64
    %369 = llvm.mul %25, %20  : i64
    %370 = llvm.add %368, %369  : i64
    %371 = llvm.add %370, %342  : i64
    %372 = llvm.getelementptr %arg5[%371] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %365, %372 : f32, !llvm.ptr
    %373 = llvm.add %31, %15  : i64
    %374 = llvm.mul %24, %22  : i64
    %375 = llvm.mul %24, %21  : i64
    %376 = llvm.add %374, %375  : i64
    %377 = llvm.mul %25, %20  : i64
    %378 = llvm.add %376, %377  : i64
    %379 = llvm.add %378, %373  : i64
    %380 = llvm.getelementptr %arg4[%379] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %381 = llvm.load %380 : !llvm.ptr -> f32
    %382 = llvm.fptrunc %0 : f64 to f32
    %383 = llvm.fadd %30, %382  : f32
    %384 = llvm.fmul %383, %2  : f32
    %385 = llvm.bitcast %383 : f32 to i32
    %386 = llvm.lshr %385, %3  : i32
    %387 = llvm.sub %4, %386  : i32
    %388 = llvm.bitcast %387 : i32 to f32
    %389 = llvm.fmul %388, %388  : f32
    %390 = llvm.fmul %389, %384  : f32
    %391 = llvm.fsub %5, %390  : f32
    %392 = llvm.fmul %391, %389  : f32
    %393 = llvm.fsub %381, %29  : f32
    %394 = llvm.fmul %393, %392  : f32
    %395 = llvm.fmul %394, %27  : f32
    %396 = llvm.fadd %395, %28  : f32
    %397 = llvm.mul %24, %22  : i64
    %398 = llvm.mul %24, %21  : i64
    %399 = llvm.add %397, %398  : i64
    %400 = llvm.mul %25, %20  : i64
    %401 = llvm.add %399, %400  : i64
    %402 = llvm.add %401, %373  : i64
    %403 = llvm.getelementptr %arg5[%402] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %396, %403 : f32, !llvm.ptr
    %404 = llvm.add %31, %16  : i64
    %405 = llvm.mul %24, %22  : i64
    %406 = llvm.mul %24, %21  : i64
    %407 = llvm.add %405, %406  : i64
    %408 = llvm.mul %25, %20  : i64
    %409 = llvm.add %407, %408  : i64
    %410 = llvm.add %409, %404  : i64
    %411 = llvm.getelementptr %arg4[%410] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %412 = llvm.load %411 : !llvm.ptr -> f32
    %413 = llvm.fptrunc %0 : f64 to f32
    %414 = llvm.fadd %30, %413  : f32
    %415 = llvm.fmul %414, %2  : f32
    %416 = llvm.bitcast %414 : f32 to i32
    %417 = llvm.lshr %416, %3  : i32
    %418 = llvm.sub %4, %417  : i32
    %419 = llvm.bitcast %418 : i32 to f32
    %420 = llvm.fmul %419, %419  : f32
    %421 = llvm.fmul %420, %415  : f32
    %422 = llvm.fsub %5, %421  : f32
    %423 = llvm.fmul %422, %420  : f32
    %424 = llvm.fsub %412, %29  : f32
    %425 = llvm.fmul %424, %423  : f32
    %426 = llvm.fmul %425, %27  : f32
    %427 = llvm.fadd %426, %28  : f32
    %428 = llvm.mul %24, %22  : i64
    %429 = llvm.mul %24, %21  : i64
    %430 = llvm.add %428, %429  : i64
    %431 = llvm.mul %25, %20  : i64
    %432 = llvm.add %430, %431  : i64
    %433 = llvm.add %432, %404  : i64
    %434 = llvm.getelementptr %arg5[%433] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %427, %434 : f32, !llvm.ptr
    %435 = llvm.add %31, %17  : i64
    %436 = llvm.mul %24, %22  : i64
    %437 = llvm.mul %24, %21  : i64
    %438 = llvm.add %436, %437  : i64
    %439 = llvm.mul %25, %20  : i64
    %440 = llvm.add %438, %439  : i64
    %441 = llvm.add %440, %435  : i64
    %442 = llvm.getelementptr %arg4[%441] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %443 = llvm.load %442 : !llvm.ptr -> f32
    %444 = llvm.fptrunc %0 : f64 to f32
    %445 = llvm.fadd %30, %444  : f32
    %446 = llvm.fmul %445, %2  : f32
    %447 = llvm.bitcast %445 : f32 to i32
    %448 = llvm.lshr %447, %3  : i32
    %449 = llvm.sub %4, %448  : i32
    %450 = llvm.bitcast %449 : i32 to f32
    %451 = llvm.fmul %450, %450  : f32
    %452 = llvm.fmul %451, %446  : f32
    %453 = llvm.fsub %5, %452  : f32
    %454 = llvm.fmul %453, %451  : f32
    %455 = llvm.fsub %443, %29  : f32
    %456 = llvm.fmul %455, %454  : f32
    %457 = llvm.fmul %456, %27  : f32
    %458 = llvm.fadd %457, %28  : f32
    %459 = llvm.mul %24, %22  : i64
    %460 = llvm.mul %24, %21  : i64
    %461 = llvm.add %459, %460  : i64
    %462 = llvm.mul %25, %20  : i64
    %463 = llvm.add %461, %462  : i64
    %464 = llvm.add %463, %435  : i64
    %465 = llvm.getelementptr %arg5[%464] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %458, %465 : f32, !llvm.ptr
    %466 = llvm.add %31, %18  : i64
    %467 = llvm.mul %24, %22  : i64
    %468 = llvm.mul %24, %21  : i64
    %469 = llvm.add %467, %468  : i64
    %470 = llvm.mul %25, %20  : i64
    %471 = llvm.add %469, %470  : i64
    %472 = llvm.add %471, %466  : i64
    %473 = llvm.getelementptr %arg4[%472] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %474 = llvm.load %473 : !llvm.ptr -> f32
    %475 = llvm.fptrunc %0 : f64 to f32
    %476 = llvm.fadd %30, %475  : f32
    %477 = llvm.fmul %476, %2  : f32
    %478 = llvm.bitcast %476 : f32 to i32
    %479 = llvm.lshr %478, %3  : i32
    %480 = llvm.sub %4, %479  : i32
    %481 = llvm.bitcast %480 : i32 to f32
    %482 = llvm.fmul %481, %481  : f32
    %483 = llvm.fmul %482, %477  : f32
    %484 = llvm.fsub %5, %483  : f32
    %485 = llvm.fmul %484, %482  : f32
    %486 = llvm.fsub %474, %29  : f32
    %487 = llvm.fmul %486, %485  : f32
    %488 = llvm.fmul %487, %27  : f32
    %489 = llvm.fadd %488, %28  : f32
    %490 = llvm.mul %24, %22  : i64
    %491 = llvm.mul %24, %21  : i64
    %492 = llvm.add %490, %491  : i64
    %493 = llvm.mul %25, %20  : i64
    %494 = llvm.add %492, %493  : i64
    %495 = llvm.add %494, %466  : i64
    %496 = llvm.getelementptr %arg5[%495] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %489, %496 : f32, !llvm.ptr
    %497 = llvm.add %31, %19  : i64
    %498 = llvm.mul %24, %22  : i64
    %499 = llvm.mul %24, %21  : i64
    %500 = llvm.add %498, %499  : i64
    %501 = llvm.mul %25, %20  : i64
    %502 = llvm.add %500, %501  : i64
    %503 = llvm.add %502, %497  : i64
    %504 = llvm.getelementptr %arg4[%503] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %505 = llvm.load %504 : !llvm.ptr -> f32
    %506 = llvm.fptrunc %0 : f64 to f32
    %507 = llvm.fadd %30, %506  : f32
    %508 = llvm.fmul %507, %2  : f32
    %509 = llvm.bitcast %507 : f32 to i32
    %510 = llvm.lshr %509, %3  : i32
    %511 = llvm.sub %4, %510  : i32
    %512 = llvm.bitcast %511 : i32 to f32
    %513 = llvm.fmul %512, %512  : f32
    %514 = llvm.fmul %513, %508  : f32
    %515 = llvm.fsub %5, %514  : f32
    %516 = llvm.fmul %515, %513  : f32
    %517 = llvm.fsub %505, %29  : f32
    %518 = llvm.fmul %517, %516  : f32
    %519 = llvm.fmul %518, %27  : f32
    %520 = llvm.fadd %519, %28  : f32
    %521 = llvm.mul %24, %22  : i64
    %522 = llvm.mul %24, %21  : i64
    %523 = llvm.add %521, %522  : i64
    %524 = llvm.mul %25, %20  : i64
    %525 = llvm.add %523, %524  : i64
    %526 = llvm.add %525, %497  : i64
    %527 = llvm.getelementptr %arg5[%526] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %520, %527 : f32, !llvm.ptr
    %528 = llvm.add %31, %1  : i64
    llvm.br ^bb4(%528 : i64)
  ^bb6:  // pred: ^bb4
    %529 = llvm.add %25, %23  : i64
    llvm.br ^bb2(%529 : i64)
  ^bb7:  // pred: ^bb2
    llvm.return
  }
}

