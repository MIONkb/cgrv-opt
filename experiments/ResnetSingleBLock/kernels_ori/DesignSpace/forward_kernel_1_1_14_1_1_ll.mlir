module attributes {llvm.data_layout = ""} {
  llvm.func @forward_kernel_1(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr) attributes {Kernel, forward_kernel_1} {
    %0 = llvm.mlir.constant(1.000000e-05 : f64) : f64
    %1 = llvm.mlir.constant(16 : index) : i64
    %2 = llvm.mlir.constant(14 : index) : i64
    %3 = llvm.mlir.constant(5.000000e-01 : f32) : f32
    %4 = llvm.mlir.constant(1 : i32) : i32
    %5 = llvm.mlir.constant(1597463007 : i32) : i32
    %6 = llvm.mlir.constant(1.500000e+00 : f32) : f32
    %7 = llvm.mlir.constant(2 : index) : i64
    %8 = llvm.mlir.constant(3 : index) : i64
    %9 = llvm.mlir.constant(4 : index) : i64
    %10 = llvm.mlir.constant(5 : index) : i64
    %11 = llvm.mlir.constant(6 : index) : i64
    %12 = llvm.mlir.constant(7 : index) : i64
    %13 = llvm.mlir.constant(8 : index) : i64
    %14 = llvm.mlir.constant(9 : index) : i64
    %15 = llvm.mlir.constant(10 : index) : i64
    %16 = llvm.mlir.constant(11 : index) : i64
    %17 = llvm.mlir.constant(12 : index) : i64
    %18 = llvm.mlir.constant(13 : index) : i64
    %19 = llvm.mlir.constant(112 : index) : i64
    %20 = llvm.mlir.constant(12544 : index) : i64
    %21 = llvm.mlir.constant(802816 : index) : i64
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = llvm.mlir.constant(0 : index) : i64
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    llvm.br ^bb2(%23 : i64)
  ^bb2(%24: i64):  // 2 preds: ^bb1, ^bb6
    %25 = llvm.icmp "slt" %24, %1 : i64
    llvm.cond_br %25, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %26 = llvm.load %arg0 : !llvm.ptr -> f32
    %27 = llvm.load %arg1 : !llvm.ptr -> f32
    %28 = llvm.load %arg2 : !llvm.ptr -> f32
    %29 = llvm.load %arg3 : !llvm.ptr -> f32
    llvm.br ^bb4(%23 : i64)
  ^bb4(%30: i64):  // 2 preds: ^bb3, ^bb5
    %31 = llvm.icmp "slt" %30, %19 : i64
    llvm.cond_br %31, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %32 = llvm.mul %23, %21  : i64
    %33 = llvm.mul %23, %20  : i64
    %34 = llvm.add %32, %33  : i64
    %35 = llvm.mul %24, %19  : i64
    %36 = llvm.add %34, %35  : i64
    %37 = llvm.add %36, %30  : i64
    %38 = llvm.getelementptr %arg4[%37] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %39 = llvm.load %38 : !llvm.ptr -> f32
    %40 = llvm.fptrunc %0 : f64 to f32
    %41 = llvm.fadd %29, %40  : f32
    %42 = llvm.fmul %41, %3  : f32
    %43 = llvm.bitcast %41 : f32 to i32
    %44 = llvm.lshr %43, %4  : i32
    %45 = llvm.sub %5, %44  : i32
    %46 = llvm.bitcast %45 : i32 to f32
    %47 = llvm.fmul %46, %46  : f32
    %48 = llvm.fmul %47, %42  : f32
    %49 = llvm.fsub %6, %48  : f32
    %50 = llvm.fmul %49, %47  : f32
    %51 = llvm.fsub %39, %28  : f32
    %52 = llvm.fmul %51, %50  : f32
    %53 = llvm.fmul %52, %26  : f32
    %54 = llvm.fadd %53, %27  : f32
    %55 = llvm.mul %23, %21  : i64
    %56 = llvm.mul %23, %20  : i64
    %57 = llvm.add %55, %56  : i64
    %58 = llvm.mul %24, %19  : i64
    %59 = llvm.add %57, %58  : i64
    %60 = llvm.add %59, %30  : i64
    %61 = llvm.getelementptr %arg5[%60] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %54, %61 : f32, !llvm.ptr
    %62 = llvm.add %30, %22  : i64
    %63 = llvm.mul %23, %21  : i64
    %64 = llvm.mul %23, %20  : i64
    %65 = llvm.add %63, %64  : i64
    %66 = llvm.mul %24, %19  : i64
    %67 = llvm.add %65, %66  : i64
    %68 = llvm.add %67, %62  : i64
    %69 = llvm.getelementptr %arg4[%68] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %70 = llvm.load %69 : !llvm.ptr -> f32
    %71 = llvm.fptrunc %0 : f64 to f32
    %72 = llvm.fadd %29, %71  : f32
    %73 = llvm.fmul %72, %3  : f32
    %74 = llvm.bitcast %72 : f32 to i32
    %75 = llvm.lshr %74, %4  : i32
    %76 = llvm.sub %5, %75  : i32
    %77 = llvm.bitcast %76 : i32 to f32
    %78 = llvm.fmul %77, %77  : f32
    %79 = llvm.fmul %78, %73  : f32
    %80 = llvm.fsub %6, %79  : f32
    %81 = llvm.fmul %80, %78  : f32
    %82 = llvm.fsub %70, %28  : f32
    %83 = llvm.fmul %82, %81  : f32
    %84 = llvm.fmul %83, %26  : f32
    %85 = llvm.fadd %84, %27  : f32
    %86 = llvm.mul %23, %21  : i64
    %87 = llvm.mul %23, %20  : i64
    %88 = llvm.add %86, %87  : i64
    %89 = llvm.mul %24, %19  : i64
    %90 = llvm.add %88, %89  : i64
    %91 = llvm.add %90, %62  : i64
    %92 = llvm.getelementptr %arg5[%91] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %85, %92 : f32, !llvm.ptr
    %93 = llvm.add %30, %7  : i64
    %94 = llvm.mul %23, %21  : i64
    %95 = llvm.mul %23, %20  : i64
    %96 = llvm.add %94, %95  : i64
    %97 = llvm.mul %24, %19  : i64
    %98 = llvm.add %96, %97  : i64
    %99 = llvm.add %98, %93  : i64
    %100 = llvm.getelementptr %arg4[%99] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %101 = llvm.load %100 : !llvm.ptr -> f32
    %102 = llvm.fptrunc %0 : f64 to f32
    %103 = llvm.fadd %29, %102  : f32
    %104 = llvm.fmul %103, %3  : f32
    %105 = llvm.bitcast %103 : f32 to i32
    %106 = llvm.lshr %105, %4  : i32
    %107 = llvm.sub %5, %106  : i32
    %108 = llvm.bitcast %107 : i32 to f32
    %109 = llvm.fmul %108, %108  : f32
    %110 = llvm.fmul %109, %104  : f32
    %111 = llvm.fsub %6, %110  : f32
    %112 = llvm.fmul %111, %109  : f32
    %113 = llvm.fsub %101, %28  : f32
    %114 = llvm.fmul %113, %112  : f32
    %115 = llvm.fmul %114, %26  : f32
    %116 = llvm.fadd %115, %27  : f32
    %117 = llvm.mul %23, %21  : i64
    %118 = llvm.mul %23, %20  : i64
    %119 = llvm.add %117, %118  : i64
    %120 = llvm.mul %24, %19  : i64
    %121 = llvm.add %119, %120  : i64
    %122 = llvm.add %121, %93  : i64
    %123 = llvm.getelementptr %arg5[%122] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %116, %123 : f32, !llvm.ptr
    %124 = llvm.add %30, %8  : i64
    %125 = llvm.mul %23, %21  : i64
    %126 = llvm.mul %23, %20  : i64
    %127 = llvm.add %125, %126  : i64
    %128 = llvm.mul %24, %19  : i64
    %129 = llvm.add %127, %128  : i64
    %130 = llvm.add %129, %124  : i64
    %131 = llvm.getelementptr %arg4[%130] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %132 = llvm.load %131 : !llvm.ptr -> f32
    %133 = llvm.fptrunc %0 : f64 to f32
    %134 = llvm.fadd %29, %133  : f32
    %135 = llvm.fmul %134, %3  : f32
    %136 = llvm.bitcast %134 : f32 to i32
    %137 = llvm.lshr %136, %4  : i32
    %138 = llvm.sub %5, %137  : i32
    %139 = llvm.bitcast %138 : i32 to f32
    %140 = llvm.fmul %139, %139  : f32
    %141 = llvm.fmul %140, %135  : f32
    %142 = llvm.fsub %6, %141  : f32
    %143 = llvm.fmul %142, %140  : f32
    %144 = llvm.fsub %132, %28  : f32
    %145 = llvm.fmul %144, %143  : f32
    %146 = llvm.fmul %145, %26  : f32
    %147 = llvm.fadd %146, %27  : f32
    %148 = llvm.mul %23, %21  : i64
    %149 = llvm.mul %23, %20  : i64
    %150 = llvm.add %148, %149  : i64
    %151 = llvm.mul %24, %19  : i64
    %152 = llvm.add %150, %151  : i64
    %153 = llvm.add %152, %124  : i64
    %154 = llvm.getelementptr %arg5[%153] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %147, %154 : f32, !llvm.ptr
    %155 = llvm.add %30, %9  : i64
    %156 = llvm.mul %23, %21  : i64
    %157 = llvm.mul %23, %20  : i64
    %158 = llvm.add %156, %157  : i64
    %159 = llvm.mul %24, %19  : i64
    %160 = llvm.add %158, %159  : i64
    %161 = llvm.add %160, %155  : i64
    %162 = llvm.getelementptr %arg4[%161] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %163 = llvm.load %162 : !llvm.ptr -> f32
    %164 = llvm.fptrunc %0 : f64 to f32
    %165 = llvm.fadd %29, %164  : f32
    %166 = llvm.fmul %165, %3  : f32
    %167 = llvm.bitcast %165 : f32 to i32
    %168 = llvm.lshr %167, %4  : i32
    %169 = llvm.sub %5, %168  : i32
    %170 = llvm.bitcast %169 : i32 to f32
    %171 = llvm.fmul %170, %170  : f32
    %172 = llvm.fmul %171, %166  : f32
    %173 = llvm.fsub %6, %172  : f32
    %174 = llvm.fmul %173, %171  : f32
    %175 = llvm.fsub %163, %28  : f32
    %176 = llvm.fmul %175, %174  : f32
    %177 = llvm.fmul %176, %26  : f32
    %178 = llvm.fadd %177, %27  : f32
    %179 = llvm.mul %23, %21  : i64
    %180 = llvm.mul %23, %20  : i64
    %181 = llvm.add %179, %180  : i64
    %182 = llvm.mul %24, %19  : i64
    %183 = llvm.add %181, %182  : i64
    %184 = llvm.add %183, %155  : i64
    %185 = llvm.getelementptr %arg5[%184] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %178, %185 : f32, !llvm.ptr
    %186 = llvm.add %30, %10  : i64
    %187 = llvm.mul %23, %21  : i64
    %188 = llvm.mul %23, %20  : i64
    %189 = llvm.add %187, %188  : i64
    %190 = llvm.mul %24, %19  : i64
    %191 = llvm.add %189, %190  : i64
    %192 = llvm.add %191, %186  : i64
    %193 = llvm.getelementptr %arg4[%192] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %194 = llvm.load %193 : !llvm.ptr -> f32
    %195 = llvm.fptrunc %0 : f64 to f32
    %196 = llvm.fadd %29, %195  : f32
    %197 = llvm.fmul %196, %3  : f32
    %198 = llvm.bitcast %196 : f32 to i32
    %199 = llvm.lshr %198, %4  : i32
    %200 = llvm.sub %5, %199  : i32
    %201 = llvm.bitcast %200 : i32 to f32
    %202 = llvm.fmul %201, %201  : f32
    %203 = llvm.fmul %202, %197  : f32
    %204 = llvm.fsub %6, %203  : f32
    %205 = llvm.fmul %204, %202  : f32
    %206 = llvm.fsub %194, %28  : f32
    %207 = llvm.fmul %206, %205  : f32
    %208 = llvm.fmul %207, %26  : f32
    %209 = llvm.fadd %208, %27  : f32
    %210 = llvm.mul %23, %21  : i64
    %211 = llvm.mul %23, %20  : i64
    %212 = llvm.add %210, %211  : i64
    %213 = llvm.mul %24, %19  : i64
    %214 = llvm.add %212, %213  : i64
    %215 = llvm.add %214, %186  : i64
    %216 = llvm.getelementptr %arg5[%215] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %209, %216 : f32, !llvm.ptr
    %217 = llvm.add %30, %11  : i64
    %218 = llvm.mul %23, %21  : i64
    %219 = llvm.mul %23, %20  : i64
    %220 = llvm.add %218, %219  : i64
    %221 = llvm.mul %24, %19  : i64
    %222 = llvm.add %220, %221  : i64
    %223 = llvm.add %222, %217  : i64
    %224 = llvm.getelementptr %arg4[%223] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %225 = llvm.load %224 : !llvm.ptr -> f32
    %226 = llvm.fptrunc %0 : f64 to f32
    %227 = llvm.fadd %29, %226  : f32
    %228 = llvm.fmul %227, %3  : f32
    %229 = llvm.bitcast %227 : f32 to i32
    %230 = llvm.lshr %229, %4  : i32
    %231 = llvm.sub %5, %230  : i32
    %232 = llvm.bitcast %231 : i32 to f32
    %233 = llvm.fmul %232, %232  : f32
    %234 = llvm.fmul %233, %228  : f32
    %235 = llvm.fsub %6, %234  : f32
    %236 = llvm.fmul %235, %233  : f32
    %237 = llvm.fsub %225, %28  : f32
    %238 = llvm.fmul %237, %236  : f32
    %239 = llvm.fmul %238, %26  : f32
    %240 = llvm.fadd %239, %27  : f32
    %241 = llvm.mul %23, %21  : i64
    %242 = llvm.mul %23, %20  : i64
    %243 = llvm.add %241, %242  : i64
    %244 = llvm.mul %24, %19  : i64
    %245 = llvm.add %243, %244  : i64
    %246 = llvm.add %245, %217  : i64
    %247 = llvm.getelementptr %arg5[%246] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %240, %247 : f32, !llvm.ptr
    %248 = llvm.add %30, %12  : i64
    %249 = llvm.mul %23, %21  : i64
    %250 = llvm.mul %23, %20  : i64
    %251 = llvm.add %249, %250  : i64
    %252 = llvm.mul %24, %19  : i64
    %253 = llvm.add %251, %252  : i64
    %254 = llvm.add %253, %248  : i64
    %255 = llvm.getelementptr %arg4[%254] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %256 = llvm.load %255 : !llvm.ptr -> f32
    %257 = llvm.fptrunc %0 : f64 to f32
    %258 = llvm.fadd %29, %257  : f32
    %259 = llvm.fmul %258, %3  : f32
    %260 = llvm.bitcast %258 : f32 to i32
    %261 = llvm.lshr %260, %4  : i32
    %262 = llvm.sub %5, %261  : i32
    %263 = llvm.bitcast %262 : i32 to f32
    %264 = llvm.fmul %263, %263  : f32
    %265 = llvm.fmul %264, %259  : f32
    %266 = llvm.fsub %6, %265  : f32
    %267 = llvm.fmul %266, %264  : f32
    %268 = llvm.fsub %256, %28  : f32
    %269 = llvm.fmul %268, %267  : f32
    %270 = llvm.fmul %269, %26  : f32
    %271 = llvm.fadd %270, %27  : f32
    %272 = llvm.mul %23, %21  : i64
    %273 = llvm.mul %23, %20  : i64
    %274 = llvm.add %272, %273  : i64
    %275 = llvm.mul %24, %19  : i64
    %276 = llvm.add %274, %275  : i64
    %277 = llvm.add %276, %248  : i64
    %278 = llvm.getelementptr %arg5[%277] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %271, %278 : f32, !llvm.ptr
    %279 = llvm.add %30, %13  : i64
    %280 = llvm.mul %23, %21  : i64
    %281 = llvm.mul %23, %20  : i64
    %282 = llvm.add %280, %281  : i64
    %283 = llvm.mul %24, %19  : i64
    %284 = llvm.add %282, %283  : i64
    %285 = llvm.add %284, %279  : i64
    %286 = llvm.getelementptr %arg4[%285] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %287 = llvm.load %286 : !llvm.ptr -> f32
    %288 = llvm.fptrunc %0 : f64 to f32
    %289 = llvm.fadd %29, %288  : f32
    %290 = llvm.fmul %289, %3  : f32
    %291 = llvm.bitcast %289 : f32 to i32
    %292 = llvm.lshr %291, %4  : i32
    %293 = llvm.sub %5, %292  : i32
    %294 = llvm.bitcast %293 : i32 to f32
    %295 = llvm.fmul %294, %294  : f32
    %296 = llvm.fmul %295, %290  : f32
    %297 = llvm.fsub %6, %296  : f32
    %298 = llvm.fmul %297, %295  : f32
    %299 = llvm.fsub %287, %28  : f32
    %300 = llvm.fmul %299, %298  : f32
    %301 = llvm.fmul %300, %26  : f32
    %302 = llvm.fadd %301, %27  : f32
    %303 = llvm.mul %23, %21  : i64
    %304 = llvm.mul %23, %20  : i64
    %305 = llvm.add %303, %304  : i64
    %306 = llvm.mul %24, %19  : i64
    %307 = llvm.add %305, %306  : i64
    %308 = llvm.add %307, %279  : i64
    %309 = llvm.getelementptr %arg5[%308] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %302, %309 : f32, !llvm.ptr
    %310 = llvm.add %30, %14  : i64
    %311 = llvm.mul %23, %21  : i64
    %312 = llvm.mul %23, %20  : i64
    %313 = llvm.add %311, %312  : i64
    %314 = llvm.mul %24, %19  : i64
    %315 = llvm.add %313, %314  : i64
    %316 = llvm.add %315, %310  : i64
    %317 = llvm.getelementptr %arg4[%316] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %318 = llvm.load %317 : !llvm.ptr -> f32
    %319 = llvm.fptrunc %0 : f64 to f32
    %320 = llvm.fadd %29, %319  : f32
    %321 = llvm.fmul %320, %3  : f32
    %322 = llvm.bitcast %320 : f32 to i32
    %323 = llvm.lshr %322, %4  : i32
    %324 = llvm.sub %5, %323  : i32
    %325 = llvm.bitcast %324 : i32 to f32
    %326 = llvm.fmul %325, %325  : f32
    %327 = llvm.fmul %326, %321  : f32
    %328 = llvm.fsub %6, %327  : f32
    %329 = llvm.fmul %328, %326  : f32
    %330 = llvm.fsub %318, %28  : f32
    %331 = llvm.fmul %330, %329  : f32
    %332 = llvm.fmul %331, %26  : f32
    %333 = llvm.fadd %332, %27  : f32
    %334 = llvm.mul %23, %21  : i64
    %335 = llvm.mul %23, %20  : i64
    %336 = llvm.add %334, %335  : i64
    %337 = llvm.mul %24, %19  : i64
    %338 = llvm.add %336, %337  : i64
    %339 = llvm.add %338, %310  : i64
    %340 = llvm.getelementptr %arg5[%339] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %333, %340 : f32, !llvm.ptr
    %341 = llvm.add %30, %15  : i64
    %342 = llvm.mul %23, %21  : i64
    %343 = llvm.mul %23, %20  : i64
    %344 = llvm.add %342, %343  : i64
    %345 = llvm.mul %24, %19  : i64
    %346 = llvm.add %344, %345  : i64
    %347 = llvm.add %346, %341  : i64
    %348 = llvm.getelementptr %arg4[%347] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %349 = llvm.load %348 : !llvm.ptr -> f32
    %350 = llvm.fptrunc %0 : f64 to f32
    %351 = llvm.fadd %29, %350  : f32
    %352 = llvm.fmul %351, %3  : f32
    %353 = llvm.bitcast %351 : f32 to i32
    %354 = llvm.lshr %353, %4  : i32
    %355 = llvm.sub %5, %354  : i32
    %356 = llvm.bitcast %355 : i32 to f32
    %357 = llvm.fmul %356, %356  : f32
    %358 = llvm.fmul %357, %352  : f32
    %359 = llvm.fsub %6, %358  : f32
    %360 = llvm.fmul %359, %357  : f32
    %361 = llvm.fsub %349, %28  : f32
    %362 = llvm.fmul %361, %360  : f32
    %363 = llvm.fmul %362, %26  : f32
    %364 = llvm.fadd %363, %27  : f32
    %365 = llvm.mul %23, %21  : i64
    %366 = llvm.mul %23, %20  : i64
    %367 = llvm.add %365, %366  : i64
    %368 = llvm.mul %24, %19  : i64
    %369 = llvm.add %367, %368  : i64
    %370 = llvm.add %369, %341  : i64
    %371 = llvm.getelementptr %arg5[%370] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %364, %371 : f32, !llvm.ptr
    %372 = llvm.add %30, %16  : i64
    %373 = llvm.mul %23, %21  : i64
    %374 = llvm.mul %23, %20  : i64
    %375 = llvm.add %373, %374  : i64
    %376 = llvm.mul %24, %19  : i64
    %377 = llvm.add %375, %376  : i64
    %378 = llvm.add %377, %372  : i64
    %379 = llvm.getelementptr %arg4[%378] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %380 = llvm.load %379 : !llvm.ptr -> f32
    %381 = llvm.fptrunc %0 : f64 to f32
    %382 = llvm.fadd %29, %381  : f32
    %383 = llvm.fmul %382, %3  : f32
    %384 = llvm.bitcast %382 : f32 to i32
    %385 = llvm.lshr %384, %4  : i32
    %386 = llvm.sub %5, %385  : i32
    %387 = llvm.bitcast %386 : i32 to f32
    %388 = llvm.fmul %387, %387  : f32
    %389 = llvm.fmul %388, %383  : f32
    %390 = llvm.fsub %6, %389  : f32
    %391 = llvm.fmul %390, %388  : f32
    %392 = llvm.fsub %380, %28  : f32
    %393 = llvm.fmul %392, %391  : f32
    %394 = llvm.fmul %393, %26  : f32
    %395 = llvm.fadd %394, %27  : f32
    %396 = llvm.mul %23, %21  : i64
    %397 = llvm.mul %23, %20  : i64
    %398 = llvm.add %396, %397  : i64
    %399 = llvm.mul %24, %19  : i64
    %400 = llvm.add %398, %399  : i64
    %401 = llvm.add %400, %372  : i64
    %402 = llvm.getelementptr %arg5[%401] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %395, %402 : f32, !llvm.ptr
    %403 = llvm.add %30, %17  : i64
    %404 = llvm.mul %23, %21  : i64
    %405 = llvm.mul %23, %20  : i64
    %406 = llvm.add %404, %405  : i64
    %407 = llvm.mul %24, %19  : i64
    %408 = llvm.add %406, %407  : i64
    %409 = llvm.add %408, %403  : i64
    %410 = llvm.getelementptr %arg4[%409] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %411 = llvm.load %410 : !llvm.ptr -> f32
    %412 = llvm.fptrunc %0 : f64 to f32
    %413 = llvm.fadd %29, %412  : f32
    %414 = llvm.fmul %413, %3  : f32
    %415 = llvm.bitcast %413 : f32 to i32
    %416 = llvm.lshr %415, %4  : i32
    %417 = llvm.sub %5, %416  : i32
    %418 = llvm.bitcast %417 : i32 to f32
    %419 = llvm.fmul %418, %418  : f32
    %420 = llvm.fmul %419, %414  : f32
    %421 = llvm.fsub %6, %420  : f32
    %422 = llvm.fmul %421, %419  : f32
    %423 = llvm.fsub %411, %28  : f32
    %424 = llvm.fmul %423, %422  : f32
    %425 = llvm.fmul %424, %26  : f32
    %426 = llvm.fadd %425, %27  : f32
    %427 = llvm.mul %23, %21  : i64
    %428 = llvm.mul %23, %20  : i64
    %429 = llvm.add %427, %428  : i64
    %430 = llvm.mul %24, %19  : i64
    %431 = llvm.add %429, %430  : i64
    %432 = llvm.add %431, %403  : i64
    %433 = llvm.getelementptr %arg5[%432] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %426, %433 : f32, !llvm.ptr
    %434 = llvm.add %30, %18  : i64
    %435 = llvm.mul %23, %21  : i64
    %436 = llvm.mul %23, %20  : i64
    %437 = llvm.add %435, %436  : i64
    %438 = llvm.mul %24, %19  : i64
    %439 = llvm.add %437, %438  : i64
    %440 = llvm.add %439, %434  : i64
    %441 = llvm.getelementptr %arg4[%440] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %442 = llvm.load %441 : !llvm.ptr -> f32
    %443 = llvm.fptrunc %0 : f64 to f32
    %444 = llvm.fadd %29, %443  : f32
    %445 = llvm.fmul %444, %3  : f32
    %446 = llvm.bitcast %444 : f32 to i32
    %447 = llvm.lshr %446, %4  : i32
    %448 = llvm.sub %5, %447  : i32
    %449 = llvm.bitcast %448 : i32 to f32
    %450 = llvm.fmul %449, %449  : f32
    %451 = llvm.fmul %450, %445  : f32
    %452 = llvm.fsub %6, %451  : f32
    %453 = llvm.fmul %452, %450  : f32
    %454 = llvm.fsub %442, %28  : f32
    %455 = llvm.fmul %454, %453  : f32
    %456 = llvm.fmul %455, %26  : f32
    %457 = llvm.fadd %456, %27  : f32
    %458 = llvm.mul %23, %21  : i64
    %459 = llvm.mul %23, %20  : i64
    %460 = llvm.add %458, %459  : i64
    %461 = llvm.mul %24, %19  : i64
    %462 = llvm.add %460, %461  : i64
    %463 = llvm.add %462, %434  : i64
    %464 = llvm.getelementptr %arg5[%463] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %457, %464 : f32, !llvm.ptr
    %465 = llvm.add %30, %2  : i64
    llvm.br ^bb4(%465 : i64)
  ^bb6:  // pred: ^bb4
    %466 = llvm.add %24, %22  : i64
    llvm.br ^bb2(%466 : i64)
  ^bb7:  // pred: ^bb2
    llvm.return
  }
}

