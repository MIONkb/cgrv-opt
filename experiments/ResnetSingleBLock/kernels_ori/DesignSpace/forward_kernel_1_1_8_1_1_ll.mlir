module attributes {llvm.data_layout = ""} {
  llvm.func @forward_kernel_1(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr, %arg3: !llvm.ptr, %arg4: !llvm.ptr, %arg5: !llvm.ptr) attributes {Kernel, forward_kernel_1} {
    %0 = llvm.mlir.constant(1.000000e-05 : f64) : f64
    %1 = llvm.mlir.constant(16 : index) : i64
    %2 = llvm.mlir.constant(8 : index) : i64
    %3 = llvm.mlir.constant(5.000000e-01 : f32) : f32
    %4 = llvm.mlir.constant(1 : i32) : i32
    %5 = llvm.mlir.constant(1597463007 : i32) : i32
    %6 = llvm.mlir.constant(1.500000e+00 : f32) : f32
    %7 = llvm.mlir.constant(2 : index) : i64
    %8 = llvm.mlir.constant(3 : index) : i64
    %9 = llvm.mlir.constant(4 : index) : i64
    %10 = llvm.mlir.constant(5 : index) : i64
    %11 = llvm.mlir.constant(6 : index) : i64
    %12 = llvm.mlir.constant(7 : index) : i64
    %13 = llvm.mlir.constant(112 : index) : i64
    %14 = llvm.mlir.constant(12544 : index) : i64
    %15 = llvm.mlir.constant(802816 : index) : i64
    %16 = llvm.mlir.constant(1 : index) : i64
    %17 = llvm.mlir.constant(0 : index) : i64
    llvm.br ^bb1
  ^bb1:  // pred: ^bb0
    llvm.br ^bb2(%17 : i64)
  ^bb2(%18: i64):  // 2 preds: ^bb1, ^bb6
    %19 = llvm.icmp "slt" %18, %1 : i64
    llvm.cond_br %19, ^bb3, ^bb7
  ^bb3:  // pred: ^bb2
    %20 = llvm.load %arg0 : !llvm.ptr -> f32
    %21 = llvm.load %arg1 : !llvm.ptr -> f32
    %22 = llvm.load %arg2 : !llvm.ptr -> f32
    %23 = llvm.load %arg3 : !llvm.ptr -> f32
    llvm.br ^bb4(%17 : i64)
  ^bb4(%24: i64):  // 2 preds: ^bb3, ^bb5
    %25 = llvm.icmp "slt" %24, %13 : i64
    llvm.cond_br %25, ^bb5, ^bb6
  ^bb5:  // pred: ^bb4
    %26 = llvm.mul %17, %15  : i64
    %27 = llvm.mul %17, %14  : i64
    %28 = llvm.add %26, %27  : i64
    %29 = llvm.mul %18, %13  : i64
    %30 = llvm.add %28, %29  : i64
    %31 = llvm.add %30, %24  : i64
    %32 = llvm.getelementptr %arg4[%31] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %33 = llvm.load %32 : !llvm.ptr -> f32
    %34 = llvm.fptrunc %0 : f64 to f32
    %35 = llvm.fadd %23, %34  : f32
    %36 = llvm.fmul %35, %3  : f32
    %37 = llvm.bitcast %35 : f32 to i32
    %38 = llvm.lshr %37, %4  : i32
    %39 = llvm.sub %5, %38  : i32
    %40 = llvm.bitcast %39 : i32 to f32
    %41 = llvm.fmul %40, %40  : f32
    %42 = llvm.fmul %41, %36  : f32
    %43 = llvm.fsub %6, %42  : f32
    %44 = llvm.fmul %43, %41  : f32
    %45 = llvm.fsub %33, %22  : f32
    %46 = llvm.fmul %45, %44  : f32
    %47 = llvm.fmul %46, %20  : f32
    %48 = llvm.fadd %47, %21  : f32
    %49 = llvm.mul %17, %15  : i64
    %50 = llvm.mul %17, %14  : i64
    %51 = llvm.add %49, %50  : i64
    %52 = llvm.mul %18, %13  : i64
    %53 = llvm.add %51, %52  : i64
    %54 = llvm.add %53, %24  : i64
    %55 = llvm.getelementptr %arg5[%54] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %48, %55 : f32, !llvm.ptr
    %56 = llvm.add %24, %16  : i64
    %57 = llvm.mul %17, %15  : i64
    %58 = llvm.mul %17, %14  : i64
    %59 = llvm.add %57, %58  : i64
    %60 = llvm.mul %18, %13  : i64
    %61 = llvm.add %59, %60  : i64
    %62 = llvm.add %61, %56  : i64
    %63 = llvm.getelementptr %arg4[%62] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %64 = llvm.load %63 : !llvm.ptr -> f32
    %65 = llvm.fptrunc %0 : f64 to f32
    %66 = llvm.fadd %23, %65  : f32
    %67 = llvm.fmul %66, %3  : f32
    %68 = llvm.bitcast %66 : f32 to i32
    %69 = llvm.lshr %68, %4  : i32
    %70 = llvm.sub %5, %69  : i32
    %71 = llvm.bitcast %70 : i32 to f32
    %72 = llvm.fmul %71, %71  : f32
    %73 = llvm.fmul %72, %67  : f32
    %74 = llvm.fsub %6, %73  : f32
    %75 = llvm.fmul %74, %72  : f32
    %76 = llvm.fsub %64, %22  : f32
    %77 = llvm.fmul %76, %75  : f32
    %78 = llvm.fmul %77, %20  : f32
    %79 = llvm.fadd %78, %21  : f32
    %80 = llvm.mul %17, %15  : i64
    %81 = llvm.mul %17, %14  : i64
    %82 = llvm.add %80, %81  : i64
    %83 = llvm.mul %18, %13  : i64
    %84 = llvm.add %82, %83  : i64
    %85 = llvm.add %84, %56  : i64
    %86 = llvm.getelementptr %arg5[%85] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %79, %86 : f32, !llvm.ptr
    %87 = llvm.add %24, %7  : i64
    %88 = llvm.mul %17, %15  : i64
    %89 = llvm.mul %17, %14  : i64
    %90 = llvm.add %88, %89  : i64
    %91 = llvm.mul %18, %13  : i64
    %92 = llvm.add %90, %91  : i64
    %93 = llvm.add %92, %87  : i64
    %94 = llvm.getelementptr %arg4[%93] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %95 = llvm.load %94 : !llvm.ptr -> f32
    %96 = llvm.fptrunc %0 : f64 to f32
    %97 = llvm.fadd %23, %96  : f32
    %98 = llvm.fmul %97, %3  : f32
    %99 = llvm.bitcast %97 : f32 to i32
    %100 = llvm.lshr %99, %4  : i32
    %101 = llvm.sub %5, %100  : i32
    %102 = llvm.bitcast %101 : i32 to f32
    %103 = llvm.fmul %102, %102  : f32
    %104 = llvm.fmul %103, %98  : f32
    %105 = llvm.fsub %6, %104  : f32
    %106 = llvm.fmul %105, %103  : f32
    %107 = llvm.fsub %95, %22  : f32
    %108 = llvm.fmul %107, %106  : f32
    %109 = llvm.fmul %108, %20  : f32
    %110 = llvm.fadd %109, %21  : f32
    %111 = llvm.mul %17, %15  : i64
    %112 = llvm.mul %17, %14  : i64
    %113 = llvm.add %111, %112  : i64
    %114 = llvm.mul %18, %13  : i64
    %115 = llvm.add %113, %114  : i64
    %116 = llvm.add %115, %87  : i64
    %117 = llvm.getelementptr %arg5[%116] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %110, %117 : f32, !llvm.ptr
    %118 = llvm.add %24, %8  : i64
    %119 = llvm.mul %17, %15  : i64
    %120 = llvm.mul %17, %14  : i64
    %121 = llvm.add %119, %120  : i64
    %122 = llvm.mul %18, %13  : i64
    %123 = llvm.add %121, %122  : i64
    %124 = llvm.add %123, %118  : i64
    %125 = llvm.getelementptr %arg4[%124] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %126 = llvm.load %125 : !llvm.ptr -> f32
    %127 = llvm.fptrunc %0 : f64 to f32
    %128 = llvm.fadd %23, %127  : f32
    %129 = llvm.fmul %128, %3  : f32
    %130 = llvm.bitcast %128 : f32 to i32
    %131 = llvm.lshr %130, %4  : i32
    %132 = llvm.sub %5, %131  : i32
    %133 = llvm.bitcast %132 : i32 to f32
    %134 = llvm.fmul %133, %133  : f32
    %135 = llvm.fmul %134, %129  : f32
    %136 = llvm.fsub %6, %135  : f32
    %137 = llvm.fmul %136, %134  : f32
    %138 = llvm.fsub %126, %22  : f32
    %139 = llvm.fmul %138, %137  : f32
    %140 = llvm.fmul %139, %20  : f32
    %141 = llvm.fadd %140, %21  : f32
    %142 = llvm.mul %17, %15  : i64
    %143 = llvm.mul %17, %14  : i64
    %144 = llvm.add %142, %143  : i64
    %145 = llvm.mul %18, %13  : i64
    %146 = llvm.add %144, %145  : i64
    %147 = llvm.add %146, %118  : i64
    %148 = llvm.getelementptr %arg5[%147] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %141, %148 : f32, !llvm.ptr
    %149 = llvm.add %24, %9  : i64
    %150 = llvm.mul %17, %15  : i64
    %151 = llvm.mul %17, %14  : i64
    %152 = llvm.add %150, %151  : i64
    %153 = llvm.mul %18, %13  : i64
    %154 = llvm.add %152, %153  : i64
    %155 = llvm.add %154, %149  : i64
    %156 = llvm.getelementptr %arg4[%155] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %157 = llvm.load %156 : !llvm.ptr -> f32
    %158 = llvm.fptrunc %0 : f64 to f32
    %159 = llvm.fadd %23, %158  : f32
    %160 = llvm.fmul %159, %3  : f32
    %161 = llvm.bitcast %159 : f32 to i32
    %162 = llvm.lshr %161, %4  : i32
    %163 = llvm.sub %5, %162  : i32
    %164 = llvm.bitcast %163 : i32 to f32
    %165 = llvm.fmul %164, %164  : f32
    %166 = llvm.fmul %165, %160  : f32
    %167 = llvm.fsub %6, %166  : f32
    %168 = llvm.fmul %167, %165  : f32
    %169 = llvm.fsub %157, %22  : f32
    %170 = llvm.fmul %169, %168  : f32
    %171 = llvm.fmul %170, %20  : f32
    %172 = llvm.fadd %171, %21  : f32
    %173 = llvm.mul %17, %15  : i64
    %174 = llvm.mul %17, %14  : i64
    %175 = llvm.add %173, %174  : i64
    %176 = llvm.mul %18, %13  : i64
    %177 = llvm.add %175, %176  : i64
    %178 = llvm.add %177, %149  : i64
    %179 = llvm.getelementptr %arg5[%178] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %172, %179 : f32, !llvm.ptr
    %180 = llvm.add %24, %10  : i64
    %181 = llvm.mul %17, %15  : i64
    %182 = llvm.mul %17, %14  : i64
    %183 = llvm.add %181, %182  : i64
    %184 = llvm.mul %18, %13  : i64
    %185 = llvm.add %183, %184  : i64
    %186 = llvm.add %185, %180  : i64
    %187 = llvm.getelementptr %arg4[%186] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %188 = llvm.load %187 : !llvm.ptr -> f32
    %189 = llvm.fptrunc %0 : f64 to f32
    %190 = llvm.fadd %23, %189  : f32
    %191 = llvm.fmul %190, %3  : f32
    %192 = llvm.bitcast %190 : f32 to i32
    %193 = llvm.lshr %192, %4  : i32
    %194 = llvm.sub %5, %193  : i32
    %195 = llvm.bitcast %194 : i32 to f32
    %196 = llvm.fmul %195, %195  : f32
    %197 = llvm.fmul %196, %191  : f32
    %198 = llvm.fsub %6, %197  : f32
    %199 = llvm.fmul %198, %196  : f32
    %200 = llvm.fsub %188, %22  : f32
    %201 = llvm.fmul %200, %199  : f32
    %202 = llvm.fmul %201, %20  : f32
    %203 = llvm.fadd %202, %21  : f32
    %204 = llvm.mul %17, %15  : i64
    %205 = llvm.mul %17, %14  : i64
    %206 = llvm.add %204, %205  : i64
    %207 = llvm.mul %18, %13  : i64
    %208 = llvm.add %206, %207  : i64
    %209 = llvm.add %208, %180  : i64
    %210 = llvm.getelementptr %arg5[%209] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %203, %210 : f32, !llvm.ptr
    %211 = llvm.add %24, %11  : i64
    %212 = llvm.mul %17, %15  : i64
    %213 = llvm.mul %17, %14  : i64
    %214 = llvm.add %212, %213  : i64
    %215 = llvm.mul %18, %13  : i64
    %216 = llvm.add %214, %215  : i64
    %217 = llvm.add %216, %211  : i64
    %218 = llvm.getelementptr %arg4[%217] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %219 = llvm.load %218 : !llvm.ptr -> f32
    %220 = llvm.fptrunc %0 : f64 to f32
    %221 = llvm.fadd %23, %220  : f32
    %222 = llvm.fmul %221, %3  : f32
    %223 = llvm.bitcast %221 : f32 to i32
    %224 = llvm.lshr %223, %4  : i32
    %225 = llvm.sub %5, %224  : i32
    %226 = llvm.bitcast %225 : i32 to f32
    %227 = llvm.fmul %226, %226  : f32
    %228 = llvm.fmul %227, %222  : f32
    %229 = llvm.fsub %6, %228  : f32
    %230 = llvm.fmul %229, %227  : f32
    %231 = llvm.fsub %219, %22  : f32
    %232 = llvm.fmul %231, %230  : f32
    %233 = llvm.fmul %232, %20  : f32
    %234 = llvm.fadd %233, %21  : f32
    %235 = llvm.mul %17, %15  : i64
    %236 = llvm.mul %17, %14  : i64
    %237 = llvm.add %235, %236  : i64
    %238 = llvm.mul %18, %13  : i64
    %239 = llvm.add %237, %238  : i64
    %240 = llvm.add %239, %211  : i64
    %241 = llvm.getelementptr %arg5[%240] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %234, %241 : f32, !llvm.ptr
    %242 = llvm.add %24, %12  : i64
    %243 = llvm.mul %17, %15  : i64
    %244 = llvm.mul %17, %14  : i64
    %245 = llvm.add %243, %244  : i64
    %246 = llvm.mul %18, %13  : i64
    %247 = llvm.add %245, %246  : i64
    %248 = llvm.add %247, %242  : i64
    %249 = llvm.getelementptr %arg4[%248] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %250 = llvm.load %249 : !llvm.ptr -> f32
    %251 = llvm.fptrunc %0 : f64 to f32
    %252 = llvm.fadd %23, %251  : f32
    %253 = llvm.fmul %252, %3  : f32
    %254 = llvm.bitcast %252 : f32 to i32
    %255 = llvm.lshr %254, %4  : i32
    %256 = llvm.sub %5, %255  : i32
    %257 = llvm.bitcast %256 : i32 to f32
    %258 = llvm.fmul %257, %257  : f32
    %259 = llvm.fmul %258, %253  : f32
    %260 = llvm.fsub %6, %259  : f32
    %261 = llvm.fmul %260, %258  : f32
    %262 = llvm.fsub %250, %22  : f32
    %263 = llvm.fmul %262, %261  : f32
    %264 = llvm.fmul %263, %20  : f32
    %265 = llvm.fadd %264, %21  : f32
    %266 = llvm.mul %17, %15  : i64
    %267 = llvm.mul %17, %14  : i64
    %268 = llvm.add %266, %267  : i64
    %269 = llvm.mul %18, %13  : i64
    %270 = llvm.add %268, %269  : i64
    %271 = llvm.add %270, %242  : i64
    %272 = llvm.getelementptr %arg5[%271] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %265, %272 : f32, !llvm.ptr
    %273 = llvm.add %24, %2  : i64
    llvm.br ^bb4(%273 : i64)
  ^bb6:  // pred: ^bb4
    %274 = llvm.add %18, %16  : i64
    llvm.br ^bb2(%274 : i64)
  ^bb7:  // pred: ^bb2
    llvm.return
  }
}

